{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biostat M280 Homework 3\n",
    "\n",
    "**Due Friday, May 25 @ 11:59PM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 - Big $n$ regression\n",
    "\n",
    "Those who took my _203B: Introduction to Data Science_ last quarter had a (painful) experience of wrangling an Apache Spark cluster to do linear regression on a dataset with more than 100 million observations. Now we learnt various methods for solving linear regression and should realize that, with right choice of algorithm, it is a problem that can be handled by any moderate computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1(1)\n",
    "\n",
    "Download the flight data from <http://stat-computing.org/dataexpo/2009/the-data.html>. For this exercise, we only need data from years 2003-2008. If you are using Mac or Linux, you can run the following Bash script, which downloads and unzips files for all years.\n",
    "```bash\n",
    "# Download flight data by year\n",
    "for i in {1987..2008}\n",
    "  do\n",
    "    echo \"$(date) $i Download\"\n",
    "    fnam=$i.csv.bz2\n",
    "    wget -O ./$fnam http://stat-computing.org/dataexpo/2009/$fnam\n",
    "    echo \"$(date) $i unzip\"\n",
    "    bzip2 -d ./$fnam\n",
    "  done\n",
    "\n",
    "# Download airline carrier data\n",
    "wget -O ./airlines.csv http://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_UNIQUE_CARRIERS\n",
    "\n",
    "# Download airports data\n",
    "wget -O ./airports.csv https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat\n",
    "```\n",
    "Find out how many data points in each year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Q1(1)  \n",
    "\n",
    "I used countlines to get the number of data points in each year (2003-2008)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6488541\n",
      "7129271\n",
      "7140597\n",
      "7141923\n",
      "7453216\n",
      "7009729\n"
     ]
    }
   ],
   "source": [
    "# how many data points\n",
    "println(countlines(\"2003.csv\"))\n",
    "println(countlines(\"2004.csv\"))\n",
    "println(countlines(\"2005.csv\"))\n",
    "println(countlines(\"2006.csv\"))\n",
    "println(countlines(\"2007.csv\"))\n",
    "println(countlines(\"2008.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1(2) \n",
    "\n",
    "We are interested in how the time gain of a flight, defined as `DepDelay - ArrDelay`, depends on the distance traveled (`Distance`), departure delay (`DepDelay`), and carrier (`UniqueCarrier`). \n",
    "\n",
    "We want to fit a linear regression `Gain ~ 1 + Distance + DepDelay + UniqueCarrier` using data from 2003-2008. Note `UniqueCarrier` is a factor with 23 levels: \"9E\", \"AA\", \"AQ\", \"AS\", \"B6\", \"CO\", \"DH\", \"DL\", \"EV\", \"F9\", \"FL\", \"HA\", \"HP\", \"MQ\", \"NW\", \"OH\", \"OO\", \"TZ\", \"UA\", \"US\", \"WN\", \"XE\", and \"YV\". We use the dummy coding with \"9E\" as base level.\n",
    "\n",
    "Will the design matrix (in double precision) fit into the memory of you computer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Q1(2)  \n",
    "\n",
    "If we use double precision for the design matrix and use '9E' and basd level, there will be `(22+4)` columns for 2003-2008. From the Q1(1), we have alreday known that there are `(6488541+7129271+7140597+7141923+7453216+7009729) = 42363277` observations in year 2003-2008. So the design matrix could take up about `42363277 * 26 * 8 bytes = 8.8 Gb` in memory, which can not be fitted into the memory of my laptop (8Gb memory).   \n",
    "\n",
    "The following show an example to load data in 2003 into memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pkg.add(\"JuliaDB\")\n",
    "# import data from csv\n",
    "using JuliaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 57.839464 seconds (153.25 M allocations: 8.148 GiB, 24.30% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Table with 6488540 rows, 4 columns:\n",
       "DepDelay  ArrDelay  UniqueCarrier  Distance\n",
       "───────────────────────────────────────────\n",
       "-4        -1        \"UA\"           837\n",
       "-1        -3        \"UA\"           837\n",
       "29        23        \"UA\"           837\n",
       "-2        -9        \"UA\"           1835\n",
       "18        52        \"UA\"           1835\n",
       "-4        6         \"UA\"           1835\n",
       "-4        -8        \"UA\"           1835\n",
       "0         2         \"UA\"           1835\n",
       "-4        19        \"UA\"           1835\n",
       "3         4         \"UA\"           413\n",
       "-4        -23       \"UA\"           413\n",
       "-3        -19       \"UA\"           413\n",
       "⋮\n",
       "#NA       #NA       \"DL\"           1891\n",
       "29        62        \"DL\"           581\n",
       "39        66        \"DL\"           1891\n",
       "26        27        \"DL\"           1678\n",
       "114       134       \"DL\"           946\n",
       "44        53        \"DL\"           813\n",
       "16        47        \"DL\"           432\n",
       "50        54        \"DL\"           432\n",
       "-3        -5        \"DL\"           453\n",
       "3         3         \"DL\"           689\n",
       "-1        -1        \"DL\"           1929"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time yrtable = loadtable(\n",
    "    \"2003.csv\", \n",
    "    datacols = [\"DepDelay\", \"ArrDelay\", \"UniqueCarrier\", \"Distance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1(3)\n",
    "\n",
    "Review the [Summary of Linear Regression](http://hua-zhou.github.io/teaching/biostatm280-2018spring/slides/12-linreg/linreg.html) and devise a strategy to solve the linear regression.\n",
    "\n",
    "Report the estimated regression coefficients $\\widehat \\beta$, estimated variance $\\widehat \\sigma^2 = \\sum_i (y_i - \\widehat y_i)^2 / (n - 1)$, and coefficient standard errors.\n",
    "\n",
    "Hint: It took my laptop less than 3 minutes to import data and fit linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Q1(3)  \n",
    "\n",
    "Though the design matrix cannot be fitted into the memory, Cholesky and Sweep methods could solved linear regression models based on the Gram matrix $\\mathbf{X}^{T}\\mathbf{X}$ , which can be dynamically updated with incoming data. They can handle huge $n$ , moderate $p$ data sets that cannot fit into memory. Here, I used Sweep method to solve linear regression model, since it could give standard errors and so on.   \n",
    "\n",
    "In order to make linear regression scalable for large scale datasets, I compute the Gram matrix $\\mathbf{X}^{T}\\mathbf{X}$ for each year data separately and sum them together to form the final Gram matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate_xy (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mapping from variable names to X columns\n",
    "# carrier \"9E\" is used as base level\n",
    "const var2col = Dict(\n",
    "        \"Intercept\" => 1,\n",
    "        \"Distance\" => 2,\n",
    "        \"DepDelay\" => 3,\n",
    "        \"AA\" => 4,\n",
    "        \"AQ\" => 5,\n",
    "        \"AS\" => 6,\n",
    "        \"B6\" => 7,\n",
    "        \"CO\" => 8,\n",
    "        \"DH\" => 9,\n",
    "        \"DL\" => 10,\n",
    "        \"EV\" => 11,\n",
    "        \"F9\" => 12,\n",
    "        \"FL\" => 13,\n",
    "        \"HA\" => 14,\n",
    "        \"HP\" => 15,\n",
    "        \"MQ\" => 16,\n",
    "        \"NW\" => 17,\n",
    "        \"OH\" => 18,\n",
    "        \"OO\" => 19,\n",
    "        \"TZ\" => 20,\n",
    "        \"UA\" => 21,\n",
    "        \"US\" => 22,\n",
    "        \"WN\" => 23,\n",
    "        \"XE\" => 24,\n",
    "        \"YV\" => 25,\n",
    "        \"Gain\" => 26)\n",
    "# mapping from column to variable names\n",
    "const col2var = map(reverse, var2col)\n",
    "# a custom function to generate [X y] from data table\n",
    "function generate_xy(tbl::NextTable)\n",
    "    # X matrix\n",
    "    XY = zeros(length(tbl), 26)\n",
    "    # intercept term\n",
    "    @views fill!(XY[:, 1], 1)\n",
    "    # Distance term\n",
    "    @views copy!(XY[:, 2], columns(tbl, :Distance))\n",
    "    # DepDelay term\n",
    "    @views copy!(XY[:, 3], columns(tbl, :DepDelay))\n",
    "    # Dummy coding for airline\n",
    "    @inbounds for i in 1:length(tbl)\n",
    "        # yrtable[i][:UniqueCarrier] == \"9E\" && continue # base level\n",
    "        tbl[i][:UniqueCarrier] == \"9E\" && continue # base level\n",
    "        XY[i, var2col[tbl[i][:UniqueCarrier]]] = 1\n",
    "    end\n",
    "    # last column is response: gain = depdelay - arrdelay\n",
    "    XY[:, 26] = select(tbl, \n",
    "        (:DepDelay, :ArrDelay) => p -> Float64(p.DepDelay - p.ArrDelay))\n",
    "    # return\n",
    "    XY\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using SweepOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_linear_function (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fit_linear_function(p)\n",
    "    n = 0\n",
    "    Gram = zeros(p + 1, p + 1)\n",
    "    for i = 2003: 2008\n",
    "        yrtable = loadtable(string(i, \".csv\"), datacols = [\"DepDelay\", \"ArrDelay\", \"UniqueCarrier\", \"Distance\"]);\n",
    "        # drop rows with missing values\n",
    "        yrtable = dropna(yrtable)\n",
    "        xy = generate_xy(yrtable)\n",
    "        n = n + size(xy, 1)\n",
    "        Gram .= Gram + xy' * xy\n",
    "        # println(i)\n",
    "    end\n",
    "    sweep!(Gram, 1:p)\n",
    "    return n, Gram\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221.237451 seconds (484.57 M allocations: 44.809 GiB, 20.81% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(41490375, [-2.00254e-6 4.21792e-11 … 1.98347e-6 1.14033; 3.00028e10 -9.38376e-14 … -5.01596e-12 0.00164935; … ; 822290.0 3.27927e8 … -3.19909e-6 -0.202211; 6.0236e7 5.75882e10 … 1.18638e6 8.48076e9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time n, Gram = fit_linear_function(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204.4031074256946"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimated regression coefficients \n",
    "p = 25\n",
    "σ2 = Gram[p + 1, end] / (n - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25×25 SparseMatrixCSC{Float64,Int64} with 25 stored entries:\n",
       "  [1 ,  1]  =  0.0202318\n",
       "  [2 ,  2]  =  4.37958e-6\n",
       "  [3 ,  3]  =  6.88878e-5\n",
       "  [4 ,  4]  =  0.0215571\n",
       "  [5 ,  5]  =  0.0521477\n",
       "  [6 ,  6]  =  0.0250361\n",
       "  [7 ,  7]  =  0.0259154\n",
       "  [8 ,  8]  =  0.0229534\n",
       "  [9 ,  9]  =  0.0266552\n",
       "  [10, 10]  =  0.021659\n",
       "  ⋮\n",
       "  [15, 15]  =  0.0276918\n",
       "  [16, 16]  =  0.0218055\n",
       "  [17, 17]  =  0.0220088\n",
       "  [18, 18]  =  0.023446\n",
       "  [19, 19]  =  0.0217463\n",
       "  [20, 20]  =  0.0375073\n",
       "  [21, 21]  =  0.0219444\n",
       "  [22, 22]  =  0.0220022\n",
       "  [23, 23]  =  0.0209201\n",
       "  [24, 24]  =  0.0222383\n",
       "  [25, 25]  =  0.0255715"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the standart errors of coefficients\n",
    "β_var = - Diagonal(Gram[1:p, 1:p] * σ2);\n",
    "β_se = sqrt.(β_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1(4)\n",
    "\n",
    "Go to your resume/cv and claim you have experience performing analytics on data with hundred millions of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 - Google PageRank\n",
    "\n",
    "We are going to try different numerical methods learnt in class on the [Google PageRank problem](https://en.wikipedia.org/wiki/PageRank)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2(1)\n",
    "\n",
    "Let $\\mathbf{A} \\in \\{0,1\\}^{n \\times n}$ be the connectivity matrix of $n$ web pages with entries\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\ta_{ij}= \\begin{cases}\n",
    "\t1 & \\text{if page $i$ links to page $j$} \\\\\n",
    "\t0 & \\text{otherwise}\n",
    "\t\\end{cases}.\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "$r_i = \\sum_j a_{ij}$ is the out-degree of page $i$. That is $r_i$ is the number of links on page $i$. Imagine a random surfer exploring the space of $n$ pages according to the following rules.  \n",
    "\n",
    "- From a page $i$ with $r_i>0$\n",
    "    * with probability $p$, (s)he randomly chooses a link on page $i$ (uniformly) and follows that link to the next page  \n",
    "    * with probability $1-p$, (s)he randomly chooses one page from the set of all $n$ pages (uniformly) and proceeds to that page  \n",
    "- From a page $i$ with $r_i=0$ (a dangling page), (s)he randomly chooses one page from the set of all $n$ pages (uniformly) and proceeds to that page  \n",
    "    \n",
    "The process defines a Markov chain on the space of $n$ pages. Write down the transition matrix $\\mathbf{P}$ of the Markov chain as a sparse matrix plus rank-1 matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Q2(1)  \n",
    "\n",
    "\n",
    "$\n",
    "P_{ij}  = \\begin{cases}\n",
    "\t\\frac{1-p}{n} + {\\frac{a_{ij}p}{r_{i}}} & \\text{if $r_{i} \\neq 0$} \\\\\n",
    "\t\\frac{1}{n} & \\text{otherwise}\n",
    "\t\\end{cases}\n",
    "$  \n",
    "\n",
    "Write in terms of sparse matrix $\\mathbf{Q}$ plus rank-1 matrix $\\mathbf{R}$  \n",
    "\n",
    "$\n",
    "Q_{ij}  = \\begin{cases}\n",
    "\t-\\frac{p}{n} + {\\frac{a_{ij}p}{r_{i}}} & \\text{if $r_{i} \\neq 0$} \\\\\n",
    "\t0 & \\text{otherwise}\n",
    "\t\\end{cases}\n",
    "$   \n",
    "\n",
    "$\n",
    "R_{ij}  = \\frac{1}{n}\\mathbf{1}\\mathbf{1}^{T}\n",
    "$  \n",
    "\n",
    "$\n",
    "\\mathbf{P} = \\mathbf{Q} + \\mathbf{R}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Q2(2)\n",
    "\n",
    "According to standard Markov chain theory, the (random) position of the surfer converges to the stationary distribution $\\mathbf{x} = (x_1,\\ldots,x_n)^T$ of the Markov chain. $x_i$ has the natural interpretation of the proportion of times the surfer visits page $i$ in the long run. Therefore $\\mathbf{x}$ serves as page ranks: a higher $x_i$ means page $i$ is more visited. It is well-known that $\\mathbf{x}$ is the left eigenvector corresponding to the top eigenvalue 1 of the transition matrix $\\mathbf{P}$. That is $\\mathbf{P}^T \\mathbf{x} = \\mathbf{x}$. Therefore $\\mathbf{x}$ can be solved as an eigen-problem. Show that it can also be cast as solving a linear system. Since the row sums of $\\mathbf{P}$ are 1, $\\mathbf{P}$ is rank deficient. We can replace the first equation by the $\\sum_{i=1}^n x_i = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Q2(2)  \n",
    "\n",
    "\n",
    "The problem of solving eigen-problem $\\mathbf{P}^{T}\\mathbf{x} = \\mathbf{x}$ is equivalent to $(\\mathbf{P}^T-\\mathbf{I})\\mathbf{x} = \\mathbf{0}$ Since the row sums of $\\mathbf{P}$ are 1, $\\mathbf{P}$ is rank deficient, and we cannot use LU decomposition to solve it directly. In order to solve the problem, we can add another row to the original problem. \n",
    "\n",
    "$\n",
    "\\\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{P_n}^{T} - \\mathbf{I_n} \\\\\n",
    "\\mathbf{1}\n",
    "\\end{bmatrix}\\mathbf{x}= \n",
    "\\begin{bmatrix}\n",
    "\\mathbf{0_n}\\\\\n",
    "\\mathbf{1}\n",
    "\\end{bmatrix}\n",
    "\\\n",
    "$  \n",
    "\n",
    "So if we set $\\mathbf{A} =\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{P_n}^{T} - \\mathbf{I_n} \\\\\n",
    "\\mathbf{1}\n",
    "\\end{bmatrix} $ and $\\mathbf{b} = \\begin{bmatrix}\n",
    "\\mathbf{0_n}\\\\\n",
    "\\mathbf{1}\n",
    "\\end{bmatrix}$, we can solve the linear system $\\mathbf{A}\\mathbf{x}=\\mathbf{b}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2(3)\n",
    "\n",
    "Download the [`ucla.zip`](http://hua-zhou.github.io/teaching/biostatm280-2018spring/hw/hw3/ucla.zip) package from course webpage. Unzip the package, which contains two files `U.txt` and `A.txt`. `U.txt` lists the 500 URL names. `A.txt` is the $500 \\times 500$ connectivity matrix. Read data into Julia. Compute summary statistics:\n",
    "* number of pages\n",
    "* number of edges\n",
    "* number of dangling nodes (pages with no out links)\n",
    "* which page has max in-degree?\n",
    "* which page has max out-degree?\n",
    "* visualize the sparsity pattern of $\\mathbf{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Q2(3)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pkg.add(\"CSV\")\n",
    "using CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of pages is 500\n",
      "The number of edges is 11158\n"
     ]
    }
   ],
   "source": [
    "# Load the data into Julia\n",
    "data_u_loc = \"U.txt\"\n",
    "data_a_loc = \"A.txt\"\n",
    "U = CSV.read(data_u_loc, header = 0);\n",
    "A = Array(CSV.read(data_a_loc, header = 0));\n",
    "# Get the number of pages, which corresponds to the number of lines in U\n",
    "println(\"The number of pages is \", size(U, 1))\n",
    "println(\"The number of edges is \", sum(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of dangling nodes is 96\n"
     ]
    }
   ],
   "source": [
    "# Get the number of dangling nodes\n",
    "n_dangling = 0\n",
    "for row = 1:500\n",
    "    if sum(A[row, :]) == 0\n",
    "        n_dangling = n_dangling + 1\n",
    "    end\n",
    "end\n",
    "println(\"The number of dangling nodes is \", n_dangling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The page with maximum out degree 36\n",
      "1×1 DataFrames.DataFrame\n",
      "│ Row │ Column1                │\n",
      "├─────┼────────────────────────┤\n",
      "│ 1   │ http://giveto.ucla.edu │\n",
      "The page with maximum in degree 1\n",
      "1×1 DataFrames.DataFrame\n",
      "│ Row │ Column1             │\n",
      "├─────┼─────────────────────┤\n",
      "│ 1   │ http://www.ucla.edu │\n"
     ]
    }
   ],
   "source": [
    "# Keep record for maximum in-degree\n",
    "max_in = 0\n",
    "# Keep record for the index of page with maximum in-degree\n",
    "max_in_index = 0\n",
    "# Keep record for maximum out-degree\n",
    "max_out = 0\n",
    "# Keep record for the index of page with maximum out-degree\n",
    "max_out_index = 0\n",
    "for idx = 1:500\n",
    "    out_degree = sum(A[idx, :])\n",
    "    if out_degree > max_out\n",
    "        max_out = out_degree\n",
    "        max_out_index = idx\n",
    "    end\n",
    "    \n",
    "    in_degree = sum(A[:, idx])\n",
    "    if in_degree > max_in\n",
    "        max_in = in_degree\n",
    "        max_in_index = idx\n",
    "    end\n",
    "    \n",
    "end\n",
    "println(\"The page with maximum out degree \", max_out_index)\n",
    "println(U[max_out_index, :])\n",
    "println(\"The page with maximum in degree \", max_in_index)\n",
    "println(U[max_in_index, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using PyPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following picture shows the sparsity pattern of $\\mathbf{A}$, and we can see it's very sparse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "PyPlot.Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PyObject <matplotlib.image.AxesImage object at 0x1225e0690>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the Sparsity pattern of A\n",
    "spy(full(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2(4)\n",
    "\n",
    "Set the _teleportation_ parameter at $p = 0.85$. Try the following methods to solve for $\\mathbf{x}$ using the `ucla.zip` data.\n",
    "\n",
    "0. A dense linear system solver such as LU decomposition.  \n",
    "0. A simple iterative linear system solver such as Jacobi or Gauss-Seidel.   \n",
    "0. A dense eigen-solver.  \n",
    "0. A simple iterative eigen-solver such as the power method.  \n",
    "\n",
    "For iterative methods, you can use the [`IterativeSolvers.jl`](https://github.com/JuliaMath/IterativeSolvers.jl) package. Make sure to utilize the special structure of $\\mathbf{P}$ (diagonal + rank 1) to speed up the matrix-vector multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Q2(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pkg.add(\"IterativeSolvers\")\n",
    "using BenchmarkTools, IterativeSolvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use dense linear system solver (LU decomposition)  \n",
    "\n",
    "Since $\\mathbf{P}$ is rank deficient, we can add an additional row in order to use LU decomposition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct P in terms of a sparse matrix plus a rank 1 matrix\n",
    "P_sparse = zeros(size(A, 1), size(A, 2))\n",
    "for idx = 1:500\n",
    "    # compute all out degrees\n",
    "    sum_out = sum(A[idx, :])\n",
    "    if sum_out != 0\n",
    "        for idy = 1: 500\n",
    "            P_sparse[idx, idy] =  \n",
    "                A[idx, idy] * 0.85 / sum_out - 0.85 / 500\n",
    "        end\n",
    "    end\n",
    "end\n",
    "P_sparse = sparse(P_sparse)\n",
    "P_t = P_sparse' + (1 / 500) * ones(500, 500) - I\n",
    "# Augment P with one row\n",
    "P_aug = [P_t; ones(1, 500)]\n",
    "# Similarly, augment b with one row\n",
    "b = [zeros(500, 1); 1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.056282 seconds (6.42 k allocations: 2.261 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500×1 Array{Float64,2}:\n",
       " 0.0115263 \n",
       " 0.00118521\n",
       " 0.00368196\n",
       " 0.00361842\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00137118\n",
       " 0.00133263\n",
       " ⋮         \n",
       " 0.00136037\n",
       " 0.00136037\n",
       " 0.00129072\n",
       " 0.00337188\n",
       " 0.00215239\n",
       " 0.00136037\n",
       " 0.00136037\n",
       " 0.00750605\n",
       " 0.00136037\n",
       " 0.00136037\n",
       " 0.00136037\n",
       " 0.00107129"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute LU decomposition to solve linear function\n",
    "@time P_lu = lufact(P_aug);\n",
    "x = P_lu[:L] \\ (sparse(P_lu[:P]) * b)\n",
    "x_lu = P_lu[:U] \\ x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use iterative linear solver (Jacobi).  \n",
    "\n",
    "Here we don't need to augment $\\mathbf{P}$ in order to solve the linear system.  \n",
    "\n",
    "Since $\\mathbf{P}$ can be written in terms of a sparse matrix and a rank-1 matrix, we can use this structure to accelerate the calculation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the lecture notes, we can know with splitting the matrix $\\mathbf{P}$ into $\\mathbf{L} + \\mathbf{U} + \\mathbf{D}$ that the Jacobi can be written as  \n",
    "\n",
    "$$\n",
    "\\mathbf{x^{(t+1)}} = -\\mathbf{D}^{-1}\\mathbf{P}\\mathbf{x^{(t)}} + \\mathbf{x^{(t)}} + \\mathbf{D}^{-1}\\mathbf{b}\n",
    "$$  \n",
    "\n",
    "Since $\\mathbf{P}$ can be written in term of a sparse matrix $\\mathbf{Q}$ plus a rank-1 matrix $\\mathbf{R}$, and $\\mathbf{b}$ is all-zeros, we can re-write the Jacobi iteration as following:  \n",
    "\n",
    "$$\n",
    "\\mathbf{x^{(t+1)}} = -\\mathbf{D}^{-1}(\\mathbf{Q} + \\frac{1}{n}\\mathbf{1}\\mathbf{1}^{T} - \\mathbf{I})\\mathbf{x^{(t)}} + \\mathbf{x^{(t)}} + \\mathbf{D}^{-1}\\mathbf{b}\n",
    "= -\\mathbf{D}^{-1}\\mathbf{Q}\\mathbf{x^{(t)}} - \\frac{1}{n}\\mathbf{D}^{-1}\\mathbf{1}\\sum{\\mathbf{x^{(t)}}}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sparse_jacobi (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sparse_jacobi(x, Q, D, b, tol, max_iter)\n",
    "    i = 1\n",
    "    diff = 100\n",
    "    n = size(x, 1)\n",
    "    e = ones(n, 1)\n",
    "    Qx = rand(size(x, 1), size(x, 2))\n",
    "    while diff > tol\n",
    "        if i > max_iter\n",
    "            return x\n",
    "        end\n",
    "        # inv(D) is cheap, since D is diagonal matrix\n",
    "        x_next = - inv(D) * (At_mul_B!(Qx, Q, x) +  \n",
    "            e * (1 / n) * sum(x) - x) + x\n",
    "        diff = vecnorm((x_next - x))\n",
    "        x = x_next\n",
    "        i = i + 1\n",
    "    end\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = Array(CSV.read(data_a_loc, header=0));\n",
    "rowsums = sum(A, 2)\n",
    "p = 0.85\n",
    "n = 500\n",
    "Q = zeros(n, n)\n",
    "for i = 1:500\n",
    "    if rowsums[i] != 0\n",
    "        for j = 1:500\n",
    "            Q[i, j] = A[i, j] * (p / rowsums[i]) - p / n\n",
    "        end\n",
    "    end\n",
    "end\n",
    "# Use the sparsity, write P in terms of one sparse matrix and one rank-1\n",
    "Q = sparse(Q);\n",
    "# Q = Q' + 1/n - I\n",
    "D = Diagonal(Q) + Diagonal(ones(500, 500) * 1 / n - 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "inv<i>{T}</i>(D::<b>Diagonal{T}</b>) at <a href=\"https://github.com/JuliaLang/julia/tree/d386e40c17d43b79fc89d3e579fc04547241787c/base/linalg/diagonal.jl#L322\" target=\"_blank\">linalg/diagonal.jl:322</a>"
      ],
      "text/plain": [
       "inv(D::Diagonal{T}) where T in Base.LinAlg at linalg/diagonal.jl:322"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(D)\n",
    "# inv(D) is cheap\n",
    "@which inv(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500×1 Array{Float64,2}:\n",
       " 0.0115263 \n",
       " 0.00118521\n",
       " 0.00368196\n",
       " 0.00361842\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00137118\n",
       " 0.00133263\n",
       " ⋮         \n",
       " 0.00136037\n",
       " 0.00136037\n",
       " 0.00129072\n",
       " 0.00337188\n",
       " 0.00215239\n",
       " 0.00136037\n",
       " 0.00136037\n",
       " 0.00750605\n",
       " 0.00136037\n",
       " 0.00136037\n",
       " 0.00136037\n",
       " 0.00107129"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_init = rand(500, 1)\n",
    "b = zeros(500, 1)\n",
    "res = sparse_jacobi(x_init, Q, D, b, 1e-6, 400)\n",
    "res = res / sum(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use dense eigen algorithm.   \n",
    "\n",
    "$\\mathbf{x}$ is the left eigenvector corresponding to the top eigenvalue 1 of the transition matrix $\\mathbf{P}$. Then we get the real part of eigen decomposition and normalize it to get $\\mathbf{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500×500 SparseMatrixCSC{Float64,Int64} with 202000 stored entries:\n",
       "  [1  ,   1]  =  -0.0017\n",
       "  [2  ,   1]  =  -0.0017\n",
       "  [5  ,   1]  =  -0.0017\n",
       "  [6  ,   1]  =  -0.0017\n",
       "  [7  ,   1]  =  0.0369364\n",
       "  [8  ,   1]  =  0.0104429\n",
       "  [9  ,   1]  =  0.0369364\n",
       "  [10 ,   1]  =  0.0369364\n",
       "  [11 ,   1]  =  0.0171889\n",
       "  [12 ,   1]  =  0.0369364\n",
       "  ⋮\n",
       "  [489, 500]  =  -0.0017\n",
       "  [490, 500]  =  0.0257194\n",
       "  [491, 500]  =  -0.0017\n",
       "  [492, 500]  =  -0.0017\n",
       "  [493, 500]  =  -0.0017\n",
       "  [494, 500]  =  -0.0017\n",
       "  [495, 500]  =  -0.0017\n",
       "  [496, 500]  =  0.0266333\n",
       "  [497, 500]  =  -0.0017\n",
       "  [498, 500]  =  0.0266333\n",
       "  [499, 500]  =  -0.0017"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct P in terms of a sparse matrix plus a rank 1 matrix\n",
    "P_sparse = zeros(size(A, 1), size(A, 2))\n",
    "for idx = 1:500\n",
    "    # compute all out degrees\n",
    "    sum_out = sum(A[idx, :])\n",
    "    if sum_out != 0\n",
    "        for idy = 1: 500\n",
    "            P_sparse[idx, idy] =  \n",
    "                A[idx, idy] * 0.85 / sum_out - 0.85 / 500\n",
    "        end\n",
    "    end\n",
    "end\n",
    "P_sparse = sparse(P_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P_sparse_eigen = P_sparse' + (1 / 500) * ones(500, 500);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500-element Array{Float64,1}:\n",
       " 0.0115263 \n",
       " 0.00118521\n",
       " 0.00368196\n",
       " 0.00361842\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00137118\n",
       " 0.00133263\n",
       " ⋮         \n",
       " 0.00136037\n",
       " 0.00136037\n",
       " 0.00129072\n",
       " 0.00337188\n",
       " 0.00215239\n",
       " 0.00136037\n",
       " 0.00136037\n",
       " 0.00750605\n",
       " 0.00136037\n",
       " 0.00136037\n",
       " 0.00136037\n",
       " 0.00107129"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_eigen = eigfact(P_sparse_eigen)[:vectors][:, 1]\n",
    "x_eigen = real.(P_eigen) / sum(real.(P_eigen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use iterative eigen solver (power method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the lecture note, we can see the power method can be written as following.   \n",
    " \n",
    "$$\n",
    "\\mathbf{x}^{(t)} = \\frac{1}{\\|\\mathbf{P} \\mathbf{x}^{(t-1)}\\|_2} \\mathbf{P}\\mathbf{x}^{(t-1)}\n",
    "$$  \n",
    "\n",
    "Similarly, we can make use of the structure of $\\mathbf{P}$, and write $\\mathbf{P}$ in terms of a sparse matrix and a rank-1 matrix.   \n",
    "\n",
    "$$\n",
    "\\mathbf{P}\\mathbf{x}^{(t-1)} = \\mathbf{Q}\\mathbf{x^{(t-1)}} - \\frac{1}{n}\\mathbf{1}\\sum{\\mathbf{x^{(t)}}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "power_sparse (generic function with 1 method)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function power_sparse(x, Q, tol, maxiter)\n",
    "    diff = 1000.0\n",
    "    i = 1\n",
    "    x = x ./ vecnorm(x)\n",
    "    e = ones(500, 1)\n",
    "    Qx = rand(size(x, 1), size(x, 2))\n",
    "    while diff > tol\n",
    "        if i > maxiter\n",
    "            return x / sum(x)\n",
    "        end\n",
    "        Qx = At_mul_B!(Qx, Q, x) +  e * (1 / n) * sum(x)\n",
    "        x_next =  Qx ./ vecnorm(Qx)\n",
    "        diff = vecnorm((x_next - x))\n",
    "        x = x_next\n",
    "        i = i + 1\n",
    "    end\n",
    "    return x / sum(x)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = Array(CSV.read(data_a_loc, header=0));\n",
    "rowsums = sum(A, 2)\n",
    "p = 0.85\n",
    "n = 500\n",
    "Q = zeros(n, n)\n",
    "for i = 1: 500\n",
    "    if rowsums[i] != 0\n",
    "        for j = 1: 500\n",
    "            Q[i, j] = A[i, j] * (p / rowsums[i]) - p / n\n",
    "        end\n",
    "    end\n",
    "end\n",
    "# Use the sparsity, write P in terms of one sparse matrix and one rank-1\n",
    "Q = sparse(Q);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500×1 Array{Float64,2}:\n",
       " 0.0115263 \n",
       " 0.00118521\n",
       " 0.00368197\n",
       " 0.00361842\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00118521\n",
       " 0.00137118\n",
       " 0.00133263\n",
       " ⋮         \n",
       " 0.00136037\n",
       " 0.00136037\n",
       " 0.00129072\n",
       " 0.00337188\n",
       " 0.00215239\n",
       " 0.00136037\n",
       " 0.00136037\n",
       " 0.00750606\n",
       " 0.00136037\n",
       " 0.00136037\n",
       " 0.00136037\n",
       " 0.0010713 "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_init = rand(500, 1)\n",
    "x = power_sparse(x_init, Q, 1e-6, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2(5)\n",
    "\n",
    "List the top 20 ranked URLs you found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20-element Array{Int64,1}:\n",
       " 200\n",
       " 459\n",
       "  64\n",
       "  84\n",
       " 276\n",
       " 462\n",
       "   1\n",
       "  27\n",
       "  29\n",
       " 496\n",
       "  28\n",
       "  36\n",
       "  63\n",
       "  48\n",
       "  51\n",
       "  56\n",
       "  53\n",
       "  58\n",
       "  43\n",
       "  59"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_indx = sortperm(squeeze(x_lu, 2), rev=true)[1: 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Column1</th></tr></thead><tbody><tr><th>1</th><td>http://delicious.com/save</td></tr><tr><th>2</th><td>http://hammer.ucla.edu/collections/detail/collection_id/6</td></tr><tr><th>3</th><td>http://www</td></tr><tr><th>4</th><td>http://giveto.ucla.edu/comments/feed</td></tr><tr><th>5</th><td>http://ogp.me/ns/video# product: http://ogp.me/ns/product#</td></tr><tr><th>6</th><td>http://cap.ucla.edu</td></tr><tr><th>7</th><td>http://www.ucla.edu</td></tr><tr><th>8</th><td>http://www.directory.ucla.edu</td></tr><tr><th>9</th><td>http://www.universityofcalifornia.edu</td></tr><tr><th>10</th><td>http://schema.org/Organization</td></tr><tr><th>11</th><td>http://www.registrar.ucla.edu/calendar</td></tr><tr><th>12</th><td>http://giveto.ucla.edu</td></tr><tr><th>13</th><td>http://www.magazine.ucla.edu/depts/hailhills/uncle-welton-in-westwood</td></tr><tr><th>14</th><td>http://www.magazine.ucla.edu/features/get-the-picture-the-ucla-brain-mapping-center</td></tr><tr><th>15</th><td>http://www.magazine.ucla.edu/features/hope-is-real-the-ucla-depression-grand-challenge</td></tr><tr><th>16</th><td>http://www.magazine.ucla.edu/features/splendor-in-the-trash</td></tr><tr><th>17</th><td>http://www.magazine.ucla.edu/exclusives/brotherly-love</td></tr><tr><th>18</th><td>http://www.magazine.ucla.edu/features/not-your-fathers-mba</td></tr><tr><th>19</th><td>http://www.uclalumni.net</td></tr><tr><th>20</th><td>http://www.magazine.ucla.edu/depts/style/welcome-to-the-jungle</td></tr></tbody></table>"
      ],
      "text/plain": [
       "20×1 DataFrames.DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ ├─────┼\n",
       "│ 1   │ │ 2   │ │ 3   │ │ 4   │ │ 5   │ │ 6   │ │ 7   │ │ 8   │ │ 9   │ │ 10  │ │ 11  │ │ 12  │ │ 13  │ │ 14  │ │ 15  │ │ 16  │ │ 17  │ │ 18  │ │ 19  │ │ 20  │ "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U[sorted_indx, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2(6)\n",
    "\n",
    "As of Monday May 11 2018, there are at least 1.83 billion indexed webpages on internet according to <http://www.worldwidewebsize.com/>. Explain whether each of these methods works for the PageRank problem at this scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Q2(6)  \n",
    "\n",
    "* The dense linear system solver   \n",
    "    This may not work for the PageRank problem at this scale. To solve $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$ via LU decomposition could cost $\\frac{2}{3}n^{3} + 2n^{2}$ flops. As calculated in the class, it can take millions years on a tera-flop supercomputer.  \n",
    "    \n",
    "* The dense eigen solver\n",
    "    This also not work for large-scale PageRank problems. The time complexity is $O(n^{3})$  \n",
    "    \n",
    "* The iterative methods (linear system, eigen solver)\n",
    "    These iterative methods could work for large-scale PageRank problems, since the time complexity is around $O(n^{2})$. \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "87px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
