{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biostat M280 Homework 3\n",
    "\n",
    "**Due Friday, May 25 @ 11:59PM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 - Big $n$ regression\n",
    "\n",
    "Those who took my _203B: Introduction to Data Science_ last quarter had a (painful) experience of wrangling an Apache Spark cluster to do linear regression on a dataset with more than 100 million observations. Now we learnt various methods for solving linear regression and should realize that, with right choice of algorithm, it is a problem that can be handled by any moderate computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1(1)\n",
    "\n",
    "Download the flight data from <http://stat-computing.org/dataexpo/2009/the-data.html>. For this exercise, we only need data from years 2003-2008. If you are using Mac or Linux, you can run the following Bash script, which downloads and unzips files for all years.\n",
    "```bash\n",
    "# Download flight data by year\n",
    "for i in {1987..2008}\n",
    "  do\n",
    "    echo \"$(date) $i Download\"\n",
    "    fnam=$i.csv.bz2\n",
    "    wget -O ./$fnam http://stat-computing.org/dataexpo/2009/$fnam\n",
    "    echo \"$(date) $i unzip\"\n",
    "    bzip2 -d ./$fnam\n",
    "  done\n",
    "\n",
    "# Download airline carrier data\n",
    "wget -O ./airlines.csv http://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_UNIQUE_CARRIERS\n",
    "\n",
    "# Download airports data\n",
    "wget -O ./airports.csv https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat\n",
    "```\n",
    "Find out how many data points in each year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Q1(1)  \n",
    "\n",
    "I used countlines to get the number of data points in each year (2003-2008)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6488541\n",
      "7129271\n",
      "7140597\n",
      "7141923\n",
      "7453216\n",
      "7009729\n"
     ]
    }
   ],
   "source": [
    "# how many data points\n",
    "println(countlines(\"2003.csv\"))\n",
    "println(countlines(\"2004.csv\"))\n",
    "println(countlines(\"2005.csv\"))\n",
    "println(countlines(\"2006.csv\"))\n",
    "println(countlines(\"2007.csv\"))\n",
    "println(countlines(\"2008.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1(2) \n",
    "\n",
    "We are interested in how the time gain of a flight, defined as `DepDelay - ArrDelay`, depends on the distance traveled (`Distance`), departure delay (`DepDelay`), and carrier (`UniqueCarrier`). \n",
    "\n",
    "We want to fit a linear regression `Gain ~ 1 + Distance + DepDelay + UniqueCarrier` using data from 2003-2008. Note `UniqueCarrier` is a factor with 23 levels: \"9E\", \"AA\", \"AQ\", \"AS\", \"B6\", \"CO\", \"DH\", \"DL\", \"EV\", \"F9\", \"FL\", \"HA\", \"HP\", \"MQ\", \"NW\", \"OH\", \"OO\", \"TZ\", \"UA\", \"US\", \"WN\", \"XE\", and \"YV\". We use the dummy coding with \"9E\" as base level.\n",
    "\n",
    "Will the design matrix (in double precision) fit into the memory of you computer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Q1(2)  \n",
    "\n",
    "If we use double precision for the design matrix and use '9E' and basd level, there will be `(22+4)` columns for 2003-2008. From the Q1(1), we have alreday known that there are `(6488541+7129271+7140597+7141923+7453216+7009729) = 42363277` observations in year 2003-2008. So the design matrix could take up about `42363277 * 26 * 8 bytes = 8.8 Gb` in memory, which can not be fitted into the memory of my laptop (8Gb memory).   \n",
    "\n",
    "The following show an example to load data in 2003 into memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pkg.add(\"JuliaDB\")\n",
    "# import data from csv\n",
    "using JuliaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36.232063 seconds (144.03 M allocations: 7.497 GiB, 36.01% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Table with 6488540 rows, 4 columns:\n",
       "DepDelay  ArrDelay  UniqueCarrier  Distance\n",
       "───────────────────────────────────────────\n",
       "-4        -1        \"UA\"           837\n",
       "-1        -3        \"UA\"           837\n",
       "29        23        \"UA\"           837\n",
       "-2        -9        \"UA\"           1835\n",
       "18        52        \"UA\"           1835\n",
       "-4        6         \"UA\"           1835\n",
       "-4        -8        \"UA\"           1835\n",
       "0         2         \"UA\"           1835\n",
       "-4        19        \"UA\"           1835\n",
       "3         4         \"UA\"           413\n",
       "-4        -23       \"UA\"           413\n",
       "-3        -19       \"UA\"           413\n",
       "⋮\n",
       "#NA       #NA       \"DL\"           1891\n",
       "29        62        \"DL\"           581\n",
       "39        66        \"DL\"           1891\n",
       "26        27        \"DL\"           1678\n",
       "114       134       \"DL\"           946\n",
       "44        53        \"DL\"           813\n",
       "16        47        \"DL\"           432\n",
       "50        54        \"DL\"           432\n",
       "-3        -5        \"DL\"           453\n",
       "3         3         \"DL\"           689\n",
       "-1        -1        \"DL\"           1929"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time yrtable = loadtable(\n",
    "    \"2003.csv\", \n",
    "    datacols = [\"DepDelay\", \"ArrDelay\", \"UniqueCarrier\", \"Distance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1(3)\n",
    "\n",
    "Review the [Summary of Linear Regression](http://hua-zhou.github.io/teaching/biostatm280-2018spring/slides/12-linreg/linreg.html) and devise a strategy to solve the linear regression.\n",
    "\n",
    "Report the estimated regression coefficients $\\widehat \\beta$, estimated variance $\\widehat \\sigma^2 = \\sum_i (y_i - \\widehat y_i)^2 / (n - 1)$, and coefficient standard errors.\n",
    "\n",
    "Hint: It took my laptop less than 3 minutes to import data and fit linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Q1(3)  \n",
    "\n",
    "Though the design matrix cannot be fitted into the memory, Cholesky and Sweep methods could solved linear regression models based on the Gram matrix $\\mathbf{X}^{T}\\mathbf{X}$ , which can be dynamically updated with incoming data. They can handle huge $n$ , moderate $p$ data sets that cannot fit into memory. Here, I used Sweep method to solve linear regression model, since it could give standard errors and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64,String} with 26 entries:\n",
       "  1  => \"Intercept\"\n",
       "  2  => \"Distance\"\n",
       "  16 => \"MQ\"\n",
       "  11 => \"EV\"\n",
       "  21 => \"UA\"\n",
       "  7  => \"B6\"\n",
       "  9  => \"DH\"\n",
       "  25 => \"YV\"\n",
       "  10 => \"DL\"\n",
       "  26 => \"Gain\"\n",
       "  19 => \"OO\"\n",
       "  17 => \"NW\"\n",
       "  8  => \"CO\"\n",
       "  22 => \"US\"\n",
       "  6  => \"AS\"\n",
       "  24 => \"XE\"\n",
       "  4  => \"AA\"\n",
       "  3  => \"DepDelay\"\n",
       "  5  => \"AQ\"\n",
       "  20 => \"TZ\"\n",
       "  23 => \"WN\"\n",
       "  13 => \"FL\"\n",
       "  14 => \"HA\"\n",
       "  15 => \"HP\"\n",
       "  12 => \"F9\"\n",
       "  ⋮  => ⋮"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mapping from variable names to X columns\n",
    "# carrier \"9E\" is used as base level\n",
    "const var2col = Dict(\n",
    "        \"Intercept\" => 1,\n",
    "        \"Distance\" => 2,\n",
    "        \"DepDelay\" => 3,\n",
    "        \"AA\" => 4,\n",
    "        \"AQ\" => 5,\n",
    "        \"AS\" => 6,\n",
    "        \"B6\" => 7,\n",
    "        \"CO\" => 8,\n",
    "        \"DH\" => 9,\n",
    "        \"DL\" => 10,\n",
    "        \"EV\" => 11,\n",
    "        \"F9\" => 12,\n",
    "        \"FL\" => 13,\n",
    "        \"HA\" => 14,\n",
    "        \"HP\" => 15,\n",
    "        \"MQ\" => 16,\n",
    "        \"NW\" => 17,\n",
    "        \"OH\" => 18,\n",
    "        \"OO\" => 19,\n",
    "        \"TZ\" => 20,\n",
    "        \"UA\" => 21,\n",
    "        \"US\" => 22,\n",
    "        \"WN\" => 23,\n",
    "        \"XE\" => 24,\n",
    "        \"YV\" => 25,\n",
    "        \"Gain\" => 26)\n",
    "# mapping from column to variable names\n",
    "const col2var = map(reverse, var2col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate_xy (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a custom function to generate [X y] from data table\n",
    "function generate_xy(tbl::NextTable)\n",
    "    # X matrix\n",
    "    XY = zeros(length(tbl), 26)\n",
    "    # intercept term\n",
    "    @views fill!(XY[:, 1], 1)\n",
    "    # Distance term\n",
    "    @views copy!(XY[:, 2], columns(tbl, :Distance))\n",
    "    # DepDelay term\n",
    "    @views copy!(XY[:, 3], columns(tbl, :DepDelay))\n",
    "    # Dummy coding for airline\n",
    "    @inbounds for i in 1:length(tbl)\n",
    "        # yrtable[i][:UniqueCarrier] == \"9E\" && continue # base level\n",
    "        tbl[i][:UniqueCarrier] == \"9E\" && continue # base level\n",
    "        XY[i, var2col[tbl[i][:UniqueCarrier]]] = 1\n",
    "    end\n",
    "    # last column is response: gain = depdelay - arrdelay\n",
    "    XY[:, 26] = select(tbl, \n",
    "        (:DepDelay, :ArrDelay) => p -> Float64(p.DepDelay - p.ArrDelay))\n",
    "    # return\n",
    "    XY\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using SweepOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pre-allocate memory for augmented Gram matrix\n",
    "Gram = zeros(26, 26);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yrtable = loadtable(\"2003.csv\", datacols = [\"DepDelay\", \"ArrDelay\", \"UniqueCarrier\", \"Distance\"]);\n",
    "# drop rows with missing values\n",
    "yrtable = dropna(yrtable)\n",
    "xy = generate_xy(yrtable)\n",
    "Gram .= Gram + xy' * xy;\n",
    "yrtable = loadtable(\"2004.csv\", datacols = [\"DepDelay\", \"ArrDelay\", \"UniqueCarrier\", \"Distance\"]);\n",
    "# drop rows with missing values\n",
    "yrtable = dropna(yrtable)\n",
    "xy = generate_xy(yrtable)\n",
    "Gram .= Gram + xy' * xy;\n",
    "yrtable = loadtable(\"2005.csv\", datacols = [\"DepDelay\", \"ArrDelay\", \"UniqueCarrier\", \"Distance\"]);\n",
    "# drop rows with missing values\n",
    "yrtable = dropna(yrtable)\n",
    "xy = generate_xy(yrtable)\n",
    "Gram .= Gram + xy' * xy;\n",
    "yrtable = loadtable(\"2006.csv\", datacols = [\"DepDelay\", \"ArrDelay\", \"UniqueCarrier\", \"Distance\"]);\n",
    "# drop rows with missing values\n",
    "yrtable = dropna(yrtable)\n",
    "xy = generate_xy(yrtable)\n",
    "Gram .= Gram + xy' * xy;\n",
    "yrtable = loadtable(\"2007.csv\", datacols = [\"DepDelay\", \"ArrDelay\", \"UniqueCarrier\", \"Distance\"]);\n",
    "# drop rows with missing values\n",
    "yrtable = dropna(yrtable)\n",
    "xy = generate_xy(yrtable)\n",
    "Gram .= Gram + xy' * xy;\n",
    "yrtable = loadtable(\"2008.csv\", datacols = [\"DepDelay\", \"ArrDelay\", \"UniqueCarrier\", \"Distance\"]);\n",
    "# drop rows with missing values\n",
    "yrtable = dropna(yrtable)\n",
    "xy = generate_xy(yrtable)\n",
    "Gram .= Gram + xy' * xy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26×26 Array{Float64,2}:\n",
       "     -2.00254e-6   4.21792e-11  …   1.98347e-6    1.14038   \n",
       "      6.00056e10  -9.38376e-14     -5.01596e-12   0.00164935\n",
       "      7.39642e8    5.52292e11       1.16836e-10  -0.0118811 \n",
       "      7.83252e6    8.38298e9       -1.97927e-6   -1.87235   \n",
       " 176672.0          7.50394e7       -1.98134e-6   -0.578956  \n",
       "      1.87509e6    1.66176e9    …  -1.98009e-6   -0.938504  \n",
       "      1.59823e6    1.9112e9        -1.97878e-6   -1.42253   \n",
       "      3.61881e6    4.07561e9       -1.97887e-6   -2.57632   \n",
       "      1.33937e6    5.02968e8       -1.98271e-6    1.16803   \n",
       "      6.7543e6     5.9028e9        -1.97993e-6   -2.1963    \n",
       "      3.29019e6    1.48444e9    …  -1.98278e-6    1.03927   \n",
       " 669684.0          5.95488e8       -1.97972e-6   -2.15213   \n",
       "      2.49863e6    1.66634e9       -1.98132e-6   -1.35253   \n",
       " 545718.0          3.22747e8       -1.98044e-6   -1.87254   \n",
       "      1.14985e6    1.16961e9       -1.97917e-6   -0.35081   \n",
       "      5.81972e6    2.27624e9    …  -1.98262e-6   -1.464     \n",
       "      5.28488e6    4.02797e9       -1.98034e-6   -3.62512   \n",
       "      2.82824e6    1.32801e9       -1.9822e-6    -0.00727311\n",
       "      6.04107e6    2.35079e9       -1.98236e-6   -0.4037    \n",
       " 412014.0          4.74193e8       -1.97834e-6   -3.57747   \n",
       "      5.93587e6    6.39596e9    …  -1.97923e-6   -1.14822   \n",
       "      5.30762e6    4.07368e9       -1.98051e-6   -0.883804  \n",
       "      1.27677e7    7.75151e9       -1.98156e-6    2.7485    \n",
       "      4.58092e6    2.46512e9       -1.98175e-6   -2.56727   \n",
       "      1.64458e6    6.55855e8       -3.19909e-6   -0.202261  \n",
       "      1.20472e8    1.15176e11   …   2.37276e6     1.69615e10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 25\n",
    "sweep!(Gram, 1:p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# \n",
    "n = 0\n",
    "for i = 2003: 2008\n",
    "    yrtable = loadtable(string(i, \".csv\"), datacols = [\"DepDelay\", \"ArrDelay\", \"UniqueCarrier\", \"Distance\"]);\n",
    "    # drop rows with missing values\n",
    "    yrtable = dropna(yrtable)\n",
    "    xy = generate_xy(yrtable)\n",
    "    n = n + size(xy, 1)\n",
    "    Gram .= Gram + xy' * xy\n",
    "    # println(i)\n",
    "end\n",
    "# print(Gram)\n",
    "# Fit the linear regression model using Sweep operation\n",
    "# p = 25\n",
    "# sweep!(Gram, 1:p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26×26 Array{Float64,2}:\n",
       "     -2.00254e-6   4.21792e-11  …   1.98347e-6    1.14033   \n",
       "      3.00028e10  -9.38376e-14     -5.01596e-12   0.00164935\n",
       "      3.69821e8    2.76146e11       1.16836e-10  -0.0118811 \n",
       "      3.91626e6    4.19149e9       -1.97927e-6   -1.8723    \n",
       "  88336.0          3.75197e7       -1.98134e-6   -0.5789    \n",
       " 937547.0          8.30881e8    …  -1.98009e-6   -0.938452  \n",
       " 799117.0          9.55599e8       -1.97878e-6   -1.42247   \n",
       "      1.8094e6     2.03781e9       -1.97887e-6   -2.57627   \n",
       " 669687.0          2.51484e8       -1.98271e-6    1.16808   \n",
       "      3.37715e6    2.9514e9        -1.97993e-6   -2.19625   \n",
       "      1.64509e6    7.42218e8    …  -1.98278e-6    1.03932   \n",
       " 334842.0          2.97744e8       -1.97972e-6   -2.15207   \n",
       "      1.24932e6    8.33171e8       -1.98132e-6   -1.35247   \n",
       " 272859.0          1.61374e8       -1.98044e-6   -1.87248   \n",
       " 574927.0          5.84803e8       -1.97917e-6   -0.350758  \n",
       "      2.90986e6    1.13812e9    …  -1.98262e-6   -1.46395   \n",
       "      2.64244e6    2.01399e9       -1.98034e-6   -3.62506   \n",
       "      1.41412e6    6.64003e8       -1.9822e-6    -0.00722279\n",
       "      3.02053e6    1.17539e9       -1.98236e-6   -0.40365   \n",
       " 206007.0          2.37097e8       -1.97834e-6   -3.5774    \n",
       "      2.96794e6    3.19798e9    …  -1.97923e-6   -1.14816   \n",
       "      2.65381e6    2.03684e9       -1.98051e-6   -0.883753  \n",
       "      6.38387e6    3.87575e9       -1.98156e-6    2.74855   \n",
       "      2.29046e6    1.23256e9       -1.98175e-6   -2.56721   \n",
       " 822290.0          3.27927e8       -3.19909e-6   -0.202211  \n",
       "      6.0236e7     5.75882e10   …   1.18638e6     8.48076e9 "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 25\n",
    "sweep!(Gram, 1:p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41490375"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "σ = Gram[26, end] / (n - 1)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.480761373854246e9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gram[26, end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25-element Array{Float64,1}:\n",
       "  1.14033   \n",
       "  0.00164935\n",
       " -0.0118811 \n",
       " -1.8723    \n",
       " -0.5789    \n",
       " -0.938452  \n",
       " -1.42247   \n",
       " -2.57627   \n",
       "  1.16808   \n",
       " -2.19625   \n",
       "  1.03932   \n",
       " -2.15207   \n",
       " -1.35247   \n",
       " -1.87248   \n",
       " -0.350758  \n",
       " -1.46395   \n",
       " -3.62506   \n",
       " -0.00722279\n",
       " -0.40365   \n",
       " -3.5774    \n",
       " -1.14816   \n",
       " -0.883753  \n",
       "  2.74855   \n",
       " -2.56721   \n",
       " -0.202211  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gram[1:25, end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26-element Array{Float64,1}:\n",
       "  1.14033   \n",
       "  0.00164935\n",
       " -0.0118811 \n",
       " -1.8723    \n",
       " -0.5789    \n",
       " -0.938452  \n",
       " -1.42247   \n",
       " -2.57627   \n",
       "  1.16808   \n",
       " -2.19625   \n",
       "  1.03932   \n",
       " -2.15207   \n",
       " -1.35247   \n",
       " -1.87248   \n",
       " -0.350758  \n",
       " -1.46395   \n",
       " -3.62506   \n",
       " -0.00722279\n",
       " -0.40365   \n",
       " -3.5774    \n",
       " -1.14816   \n",
       " -0.883753  \n",
       "  2.74855   \n",
       " -2.56721   \n",
       " -0.202211  \n",
       "  8.48076e9 "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gram[1:26, end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1(4)\n",
    "\n",
    "Go to your resume/cv and claim you have experience performing analytics on data with hundred millions of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample code\n",
    "\n",
    "Following code explores the data in 2003 and generates the design matrix and responses for that year. Feel free to use the code in your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year,Month,DayofMonth,DayOfWeek,DepTime,CRSDepTime,ArrTime,CRSArrTime,UniqueCarrier,FlightNum,TailNum,ActualElapsedTime,CRSElapsedTime,AirTime,ArrDelay,DepDelay,Origin,Dest,Distance,TaxiIn,TaxiOut,Cancelled,CancellationCode,Diverted,CarrierDelay,WeatherDelay,NASDelay,SecurityDelay,LateAircraftDelay\n",
      "2003,1,29,3,1651,1655,1912,1913,UA,1017,N202UA,141,138,119,-1,-4,ORD,MSY,837,5,17,0,NA,0,NA,NA,NA,NA,NA\n",
      "2003,1,30,4,1654,1655,1910,1913,UA,1017,N311UA,136,138,108,-3,-1,ORD,MSY,837,2,26,0,NA,0,NA,NA,NA,NA,NA\n",
      "2003,1,31,5,1724,1655,1936,1913,UA,1017,N317UA,132,138,110,23,29,ORD,MSY,837,5,17,0,NA,0,NA,NA,NA,NA,NA\n",
      "2003,1,1,3,1033,1035,1625,1634,UA,1018,N409UA,232,239,215,-9,-2,OAK,ORD,1835,6,11,0,NA,0,NA,NA,NA,NA,NA\n",
      "2003,1,2,4,1053,1035,1726,1634,UA,1018,N496UA,273,239,214,52,18,OAK,ORD,1835,13,46,0,NA,0,NA,NA,NA,NA,NA\n",
      "2003,1,3,5,1031,1035,1640,1634,UA,1018,N412UA,249,239,223,6,-4,OAK,ORD,1835,13,13,0,NA,0,NA,NA,NA,NA,NA\n",
      "2003,1,4,6,1031,1035,1626,1634,UA,1018,N455UA,235,239,219,-8,-4,OAK,ORD,1835,5,11,0,NA,0,NA,NA,NA,NA,NA\n",
      "2003,1,5,7,1035,1035,1636,1634,UA,1018,N828UA,241,239,227,2,0,OAK,ORD,1835,5,9,0,NA,0,NA,NA,NA,NA,NA\n",
      "2003,1,6,1,1031,1035,1653,1634,UA,1018,N453UA,262,239,241,19,-4,OAK,ORD,1835,7,14,0,NA,0,NA,NA,NA,NA,NA\n"
     ]
    }
   ],
   "source": [
    ";head 2003.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6488541"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many data points\n",
    "countlines(\"2003.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mArgumentError: Module JuliaDB not found in current path.\nRun `Pkg.add(\"JuliaDB\")` to install the JuliaDB package.\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mArgumentError: Module JuliaDB not found in current path.\nRun `Pkg.add(\"JuliaDB\")` to install the JuliaDB package.\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1m_require\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:435\u001b[22m\u001b[22m",
      " [2] \u001b[1mrequire\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:405\u001b[22m\u001b[22m",
      " [3] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:522\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "# import data from csv\n",
    "using JuliaDB\n",
    "# only need columns: DepDelay, ArrDelay, UniqueCarrier, Distance\n",
    "@time yrtable = loadtable(\n",
    "    \"2003.csv\", \n",
    "    datacols = [\"DepDelay\", \"ArrDelay\", \"UniqueCarrier\", \"Distance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table with 6375689 rows, 4 columns:\n",
       "DepDelay  ArrDelay  UniqueCarrier  Distance\n",
       "───────────────────────────────────────────\n",
       "-4        -1        \"UA\"           837\n",
       "-1        -3        \"UA\"           837\n",
       "29        23        \"UA\"           837\n",
       "-2        -9        \"UA\"           1835\n",
       "18        52        \"UA\"           1835\n",
       "-4        6         \"UA\"           1835\n",
       "-4        -8        \"UA\"           1835\n",
       "0         2         \"UA\"           1835\n",
       "-4        19        \"UA\"           1835\n",
       "3         4         \"UA\"           413\n",
       "-4        -23       \"UA\"           413\n",
       "-3        -19       \"UA\"           413\n",
       "⋮\n",
       "70        66        \"DL\"           1891\n",
       "29        62        \"DL\"           581\n",
       "39        66        \"DL\"           1891\n",
       "26        27        \"DL\"           1678\n",
       "114       134       \"DL\"           946\n",
       "44        53        \"DL\"           813\n",
       "16        47        \"DL\"           432\n",
       "50        54        \"DL\"           432\n",
       "-3        -5        \"DL\"           453\n",
       "3         3         \"DL\"           689\n",
       "-1        -1        \"DL\"           1929"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with missing values\n",
    "yrtable = dropna(yrtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate_xy (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mapping from variable names to X columns\n",
    "# carrier \"9E\" is used as base level\n",
    "const var2col = Dict(\n",
    "        \"Intercept\" => 1,\n",
    "        \"Distance\" => 2,\n",
    "        \"DepDelay\" => 3,\n",
    "        \"AA\" => 4,\n",
    "        \"AQ\" => 5,\n",
    "        \"AS\" => 6,\n",
    "        \"B6\" => 7,\n",
    "        \"CO\" => 8,\n",
    "        \"DH\" => 9,\n",
    "        \"DL\" => 10,\n",
    "        \"EV\" => 11,\n",
    "        \"F9\" => 12,\n",
    "        \"FL\" => 13,\n",
    "        \"HA\" => 14,\n",
    "        \"HP\" => 15,\n",
    "        \"MQ\" => 16,\n",
    "        \"NW\" => 17,\n",
    "        \"OH\" => 18,\n",
    "        \"OO\" => 19,\n",
    "        \"TZ\" => 20,\n",
    "        \"UA\" => 21,\n",
    "        \"US\" => 22,\n",
    "        \"WN\" => 23,\n",
    "        \"XE\" => 24,\n",
    "        \"YV\" => 25,\n",
    "        \"Gain\" => 26)\n",
    "# mapping from column to variable names\n",
    "const col2var = map(reverse, var2col)\n",
    "\n",
    "# a custom function to generate [X y] from data table\n",
    "function generate_xy(tbl::NextTable)\n",
    "    # X matrix\n",
    "    XY = zeros(length(tbl), 26)\n",
    "    # intercept term\n",
    "    @views fill!(XY[:, 1], 1)\n",
    "    # Distance term\n",
    "    @views copy!(XY[:, 2], columns(tbl, :Distance))\n",
    "    # DepDelay term\n",
    "    @views copy!(XY[:, 3], columns(tbl, :DepDelay))\n",
    "    # Dummy coding for airline\n",
    "    @inbounds for i in 1:length(tbl)\n",
    "        yrtable[i][:UniqueCarrier] == \"9E\" && continue # base level\n",
    "        XY[i, var2col[tbl[i][:UniqueCarrier]]] = 1\n",
    "    end\n",
    "    # last column is response: gain = depdelay - arrdelay\n",
    "    XY[:, 26] = select(tbl, \n",
    "        (:DepDelay, :ArrDelay) => p -> Float64(p.DepDelay - p.ArrDelay))\n",
    "    # return\n",
    "    XY\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.518327 seconds (19.38 M allocations: 1.961 GiB, 17.96% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6375689×26 Array{Float64,2}:\n",
       " 1.0   837.0   -4.0  0.0  0.0  0.0  …  0.0  1.0  0.0  0.0  0.0  0.0   -3.0\n",
       " 1.0   837.0   -1.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0    2.0\n",
       " 1.0   837.0   29.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0    6.0\n",
       " 1.0  1835.0   -2.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0    7.0\n",
       " 1.0  1835.0   18.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0  -34.0\n",
       " 1.0  1835.0   -4.0  0.0  0.0  0.0  …  0.0  1.0  0.0  0.0  0.0  0.0  -10.0\n",
       " 1.0  1835.0   -4.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0    4.0\n",
       " 1.0  1835.0    0.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0   -2.0\n",
       " 1.0  1835.0   -4.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0  -23.0\n",
       " 1.0   413.0    3.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0   -1.0\n",
       " 1.0   413.0   -4.0  0.0  0.0  0.0  …  0.0  1.0  0.0  0.0  0.0  0.0   19.0\n",
       " 1.0   413.0   -3.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0   16.0\n",
       " 1.0   413.0    0.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0   12.0\n",
       " ⋮                             ⋮    ⋱       ⋮                          ⋮  \n",
       " 1.0   406.0  104.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0   -4.0\n",
       " 1.0  1891.0   70.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0    4.0\n",
       " 1.0   581.0   29.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  -33.0\n",
       " 1.0  1891.0   39.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  -27.0\n",
       " 1.0  1678.0   26.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0   -1.0\n",
       " 1.0   946.0  114.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  -20.0\n",
       " 1.0   813.0   44.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0   -9.0\n",
       " 1.0   432.0   16.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  -31.0\n",
       " 1.0   432.0   50.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0   -4.0\n",
       " 1.0   453.0   -3.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0    2.0\n",
       " 1.0   689.0    3.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0    0.0\n",
       " 1.0  1929.0   -1.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0    0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time xy = generate_xy(yrtable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 - Google PageRank\n",
    "\n",
    "We are going to try different numerical methods learnt in class on the [Google PageRank problem](https://en.wikipedia.org/wiki/PageRank)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2(1)\n",
    "\n",
    "Let $\\mathbf{A} \\in \\{0,1\\}^{n \\times n}$ be the connectivity matrix of $n$ web pages with entries\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\ta_{ij}= \\begin{cases}\n",
    "\t1 & \\text{if page $i$ links to page $j$} \\\\\n",
    "\t0 & \\text{otherwise}\n",
    "\t\\end{cases}.\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "$r_i = \\sum_j a_{ij}$ is the out-degree of page $i$. That is $r_i$ is the number of links on page $i$. Imagine a random surfer exploring the space of $n$ pages according to the following rules.  \n",
    "\n",
    "- From a page $i$ with $r_i>0$\n",
    "    * with probability $p$, (s)he randomly chooses a link on page $i$ (uniformly) and follows that link to the next page  \n",
    "    * with probability $1-p$, (s)he randomly chooses one page from the set of all $n$ pages (uniformly) and proceeds to that page  \n",
    "- From a page $i$ with $r_i=0$ (a dangling page), (s)he randomly chooses one page from the set of all $n$ pages (uniformly) and proceeds to that page  \n",
    "    \n",
    "The process defines a Markov chain on the space of $n$ pages. Write down the transition matrix $\\mathbf{P}$ of the Markov chain as a diagonal matrix plus rank-1 matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Q2(2)\n",
    "\n",
    "According to standard Markov chain theory, the (random) position of the surfer converges to the stationary distribution $\\mathbf{x} = (x_1,\\ldots,x_n)^T$ of the Markov chain. $x_i$ has the natural interpretation of the proportion of times the surfer visits page $i$ in the long run. Therefore $\\mathbf{x}$ serves as page ranks: a higher $x_i$ means page $i$ is more visited. It is well-known that $\\mathbf{x}$ is the left eigenvector corresponding to the top eigenvalue 1 of the transition matrix $\\mathbf{P}$. That is $\\mathbf{P}^T \\mathbf{x} = \\mathbf{x}$. Therefore $\\mathbf{x}$ can be solved as an eigen-problem. Show that it can also be cast as solving a linear system. Since the row sums of $\\mathbf{P}$ are 1, $\\mathbf{P}$ is rank deficient. We can replace the first equation by the $\\sum_{i=1}^n x_i = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2(3)\n",
    "\n",
    "Download the [`ucla.zip`](http://hua-zhou.github.io/teaching/biostatm280-2018spring/hw/hw3/ucla.zip) package from course webpage. Unzip the package, which contains two files `U.txt` and `A.txt`. `U.txt` lists the 500 URL names. `A.txt` is the $500 \\times 500$ connectivity matrix. Read data into Julia. Compute summary statistics:\n",
    "* number of pages\n",
    "* number of edges\n",
    "* number of dangling nodes (pages with no out links)\n",
    "* which page has max in-degree?\n",
    "* which page has max out-degree?\n",
    "* visualize the sparsity pattern of $\\mathbf{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2(4)\n",
    "\n",
    "Set the _teleportation_ parameter at $p = 0.85$. Try the following methods to solve for $\\mathbf{x}$ using the `ucla.zip` data.\n",
    "\n",
    "0. A dense linear system solver such as LU decomposition.  \n",
    "0. A simple iterative linear system solver such as Jacobi or Gauss-Seidel.   \n",
    "0. A dense eigen-solver.  \n",
    "0. A simple iterative eigen-solver such as the power method.  \n",
    "\n",
    "For iterative methods, you can use the [`IterativeSolvers.jl`](https://github.com/JuliaMath/IterativeSolvers.jl) package. Make sure to utilize the special structure of $\\mathbf{P}$ (diagonal + rank 1) to speed up the matrix-vector multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2(5)\n",
    "\n",
    "List the top 20 ranked URLs you found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2(6)\n",
    "\n",
    "As of Monday May 11 2018, there are at least 1.83 billion indexed webpages on internet according to <http://www.worldwidewebsize.com/>. Explain whether each of these methods works for the PageRank problem at this scale."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "87px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
