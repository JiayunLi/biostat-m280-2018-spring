{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biostat M280 Homework 2\n",
    "\n",
    "**Due May 11 @ 11:59PM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Nonnegative Matrix Factorization\n",
    "\n",
    "Nonnegative matrix factorization (NNMF) was introduced by [Lee and Seung (1999)](https://www.nature.com/articles/44565) as an analog of principal components and vector quantization with applications in data compression and clustering. In this homework we consider algorithms for fitting NNMF and (optionally) high performance computing using graphical processing units (GPUs).\n",
    "\n",
    "<img src=\"./nnmf.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "In mathematical terms, one approximates a data matrix $\\mathbf{X} \\in \\mathbb{R}^{m \\times n}$ with nonnegative entries $x_{ij}$ by a product of two low-rank matrices $\\mathbf{V} \\in \\mathbb{R}^{m \\times r}$ and $\\mathbf{W} \\in \\mathbb{R}^{r \\times n}$ with nonnegative entries $v_{ik}$ and $w_{kj}$. Consider minimization of the squared Frobenius norm\n",
    "$$\n",
    "\tL(\\mathbf{V}, \\mathbf{W}) = \\|\\mathbf{X} - \\mathbf{V} \\mathbf{W}\\|_{\\text{F}}^2 = \\sum_i \\sum_j \\left(x_{ij} - \\sum_k v_{ik} w_{kj} \\right)^2, \\quad v_{ik} \\ge 0, w_{kj} \\ge 0,\n",
    "$$\n",
    "which should lead to a good factorization. Later in the course we will learn how to derive a majorization-minimization (MM) algorithm with iterative updates\n",
    "$$\n",
    "\tv_{ik}^{(t+1)} = v_{ik}^{(t)} \\frac{\\sum_j x_{ij} w_{kj}^{(t)}}{\\sum_j b_{ij}^{(t)} w_{kj}^{(t)}}, \\quad \\text{where } b_{ij}^{(t)} = \\sum_k v_{ik}^{(t)} w_{kj}^{(t)},\n",
    "$$\n",
    "$$\n",
    "\tw_{kj}^{(t+1)} = w_{kj}^{(t)} \\frac{\\sum_i x_{ij} v_{ik}^{(t+1)}}{\\sum_i b_{ij}^{(t+1/2)} v_{ik}^{(t+1)}}, \\quad \\text{where } b_{ij}^{(t+1/2)} = \\sum_k v_{ik}^{(t+1)} w_{kj}^{(t)}\n",
    "$$\n",
    "that drive the objective $L^{(t)} = L(\\mathbf{V}^{(t)}, \\mathbf{W}^{(t)})$ downhill. Superscript $t$ indicates iteration number. Efficiency (both speed and memory) will be the most important criterion when grading this problem.\n",
    "\n",
    "\n",
    "1. Implement the algorithm with arguments: $\\mathbf{X}$ (data, each row is a vectorized image), rank $r$, convergence tolerance, and optional starting point.\n",
    "```julia\n",
    "function nnmf(\n",
    "    X::Matrix{T},\n",
    "    r::Integer;\n",
    "    maxiter::Integer=1000, \n",
    "    tol::Number=1e-4,\n",
    "    V::Matrix{T}=rand(T, size(X, 1), r),\n",
    "    W::Matrix{T}=rand(T, r, size(X, 2))\n",
    "    ) where T <: AbstractFloat\n",
    "    # implementation\n",
    "    # Output\n",
    "    return V, W\n",
    "end\n",
    "```\n",
    "\n",
    "0. Database 1 from the [MIT Center for Biological and Computational Learning (CBCL)](http://cbcl.mit.edu) reduces to a matrix $\\mathbf{X}$ containing $m = 2,429$ gray-scale face images with $n = 19 \\times 19 = 361$ pixels per face. Each image (row) is scaled to have mean and standard deviation 0.25.  \n",
    "Read in the [`nnmf-2429-by-361-face.txt`](http://hua-zhou.github.io/teaching/biostatm280-2018spring/hw/hw2/nnmf-2429-by-361-face.txt) file, e.g., using [`readdlm()`](https://docs.julialang.org/en/stable/stdlib/io-network/#Base.DataFmt.readdlm-Tuple{Any,Char,Type,Char}) function, and display a couple sample images, e.g., using [ImageView.jl](https://github.com/JuliaImages/ImageView.jl) package.\n",
    "\n",
    "0. Report the run times, using `@time`, of your function for fitting NNMF on the MIT CBCL face data set at ranks $r=10, 20, 30, 40, 50$. For ease of comparison (and grading), please start your algorithm with the provided $\\mathbf{V}^{(0)}$ (first $r$ columns of [`V0.txt`](http://hua-zhou.github.io/teaching/biostatm280-2018spring/hw/hw2/V0.txt)) and $\\mathbf{W}^{(0)}$ (first $r$ rows of [`W0.txt`](http://hua-zhou.github.io/teaching/biostatm280-2018spring/hw/hw2/W0.txt)) and stopping criterion\n",
    "$$\n",
    "\t\\frac{|L^{(t+1)} - L^{(t)}|}{|L^{(t)}| + 1} \\le 10^{-4}.\n",
    "$$\n",
    "\n",
    "0. Choose an $r \\in \\{10, 20, 30, 40, 50\\}$ and start your algorithm from a different $\\mathbf{V}^{(0)}$ and $\\mathbf{W}^{(0)}$. Do you obtain the same objective value and $(\\mathbf{V}, \\mathbf{W})$? Explain what you find.\n",
    "\n",
    "0. For the same $r$, start your algorithm from $v_{ik}^{(0)} = w_{kj}^{(0)} = 1$ for all $i,j,k$. Do you obtain the same objective value and $(\\mathbf{V}, \\mathbf{W})$? Explain what you find.\n",
    "\n",
    "0. Plot the basis images (rows of $\\mathbf{W}$) at rank $r=50$. What do you find?\n",
    "\n",
    "0. (Optional) Investigate the GPU capabilities of Julia. Report the speed gain of your GPU code over CPU code at ranks $r=10, 20, 30, 40, 50$. Make sure to use the same starting point as in part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Q1(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data_loc = \"nnmf-2429-by-361-face.txt\"\n",
    "X = readdlm(data_loc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPackage ImageView is already installed\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mMETADATA is out-of-date — you may not have the latest version of ImageView\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUse `Pkg.update()` to get the latest versions of your packages\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPackage Distances is already installed\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mMETADATA is out-of-date — you may not have the latest version of Distances\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUse `Pkg.update()` to get the latest versions of your packages\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"ImageView\")\n",
    "Pkg.add(\"Distances\")\n",
    "using ImageView, Images\n",
    "using Distances\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "19×19 Array{Gray{Float64},2}:\n",
       " Gray{Float64}(0.14815)   …  Gray{Float64}(0.0)      \n",
       " Gray{Float64}(0.018294)     Gray{Float64}(0.027569) \n",
       " Gray{Float64}(0.027569)     Gray{Float64}(0.0)      \n",
       " Gray{Float64}(0.0)          Gray{Float64}(0.0090181)\n",
       " Gray{Float64}(0.083222)     Gray{Float64}(0.036844) \n",
       " Gray{Float64}(0.10177)   …  Gray{Float64}(0.064671) \n",
       " Gray{Float64}(0.38004)      Gray{Float64}(0.13887)  \n",
       " Gray{Float64}(0.51917)      Gray{Float64}(0.30583)  \n",
       " Gray{Float64}(0.43569)      Gray{Float64}(0.37076)  \n",
       " Gray{Float64}(0.38004)      Gray{Float64}(0.37076)  \n",
       " Gray{Float64}(0.29656)   …  Gray{Float64}(0.26873)  \n",
       " Gray{Float64}(0.25946)      Gray{Float64}(0.28728)  \n",
       " Gray{Float64}(0.31511)      Gray{Float64}(0.28728)  \n",
       " Gray{Float64}(0.2038)       Gray{Float64}(0.19453)  \n",
       " Gray{Float64}(0.083222)     Gray{Float64}(0.073946) \n",
       " Gray{Float64}(0.018294)  …  Gray{Float64}(0.0)      \n",
       " Gray{Float64}(0.064671)     Gray{Float64}(0.0)      \n",
       " Gray{Float64}(0.018294)     Gray{Float64}(0.0)      \n",
       " Gray{Float64}(0.0)          Gray{Float64}(0.0)      "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the image\n",
    "# Reshape the row vector to an 19*19 image\n",
    "img = reshape(X[1, :], 19, 19);\n",
    "# Display the image by converting the to Grayscale image\n",
    "img = colorview(Gray, img)  \n",
    "# convert(Array, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Q1(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnmf (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and implement NNMF algorithm\n",
    "function nnmf(\n",
    "    X::Matrix, \n",
    "    r::Int;\n",
    "    maxiter::Int=1000, \n",
    "    tol::eltype(X)=1e-4,\n",
    "    V::Matrix{eltype(X)}=rand(size(X, 1), r),\n",
    "    W::Matrix{eltype(X)}=rand(r, size(X, 2))\n",
    " )\n",
    "    pre_err = 0.0\n",
    "    err_change = 1000.0\n",
    "    t = Int(0)\n",
    "    while err_change > tol\n",
    "        if t > maxiter\n",
    "            return V, W\n",
    "        end\n",
    "        # B = *(V, W)\n",
    "        V = V .* (X * W') ./ (V * W * W')\n",
    "        B = V * W\n",
    "        W = W .* (V' * X) ./ (V' * B)\n",
    "        t = t + 1;\n",
    "        err = sqeuclidean(X, B)\n",
    "        err_change = abs(err - pre_err) / (pre_err + 1)\n",
    "        pre_err = err\n",
    "        # println(err_change)\n",
    "    end\n",
    "    return V, W, pre_err\n",
    " # implementation\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Q1(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v_data_loc = \"V0.txt\"\n",
    "w_data_loc = \"W0.txt\"\n",
    "V_init = readdlm(v_data_loc);\n",
    "W_init = readdlm(w_data_loc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.991769 seconds (4.80 k allocations: 3.279 GiB, 11.46% gc time)\n"
     ]
    }
   ],
   "source": [
    "# Report time r = 10\n",
    "r = 10\n",
    "@time V, W, pre_err = nnmf(X, r, V = V_init[:, 1:r], W = W_init[1:r, :]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10.966193 seconds (7.90 k allocations: 5.662 GiB, 11.23% gc time)\n"
     ]
    }
   ],
   "source": [
    "# Report time r = 20\n",
    "r = 20\n",
    "@time V, W, pre_err = nnmf(X, r, V = V_init[:, 1:r], W = W_init[1:r, :]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15.076644 seconds (9.66 k allocations: 7.240 GiB, 9.56% gc time)\n"
     ]
    }
   ],
   "source": [
    "# Report time r = 30\n",
    "r = 30\n",
    "@time V, W, pre_err = nnmf(X, r, V = V_init[:, 1:r], W = W_init[1:r, :]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19.168610 seconds (11.64 k allocations: 9.105 GiB, 9.03% gc time)\n"
     ]
    }
   ],
   "source": [
    "# Report time r = 40\n",
    "r = 40\n",
    "@time V, W, pre_err = nnmf(X, r, V = V_init[:, 1:r], W = W_init[1:r, :]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26.059584 seconds (13.98 k allocations: 11.392 GiB, 7.91% gc time)\n"
     ]
    }
   ],
   "source": [
    "# Report time r = 50\n",
    "r = 50\n",
    "@time V, W, pre_err = nnmf(X, r, V = V_init[:, 1:r], W = W_init[1:r, :]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Q1(4)  \n",
    "\n",
    "I select r = 20, and run the algorithm with predefined V, W or random V, W.  \n",
    "\n",
    "The following shows that different start points can lead to different solutions.   \n",
    "The objective function may not be convex, and could have many different local minimums. The iterative algorithm can converge at different local minimums, which cause different solutions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\n",
      "false\n",
      "false\n"
     ]
    }
   ],
   "source": [
    "# Select r = 20, first get result using pre-defined V, W\n",
    "r = 20\n",
    "srand(1234)\n",
    "V1, W1, pre_err1 = nnmf(X, r, V = V_init[:, 1:r], W = W_init[1:r, :]);\n",
    "\n",
    "V2, W2, pre_err2 = \n",
    "    nnmf(X, r, V = rand(size(X, 1), r), W = rand(r, size(X, 2)));\n",
    "println(pre_err1 == pre_err2)\n",
    "println(V1 == V2)\n",
    "println(W1 == W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "true\n",
      "true\n"
     ]
    }
   ],
   "source": [
    "V3, W3, pre_err3 = \n",
    "    nnmf(X, r, V = ones(size(X, 1), r), W = ones(r, size(X, 2)));\n",
    "V4, W4, pre_err4 = \n",
    "    nnmf(X, r, V = ones(size(X, 1), r), W = ones(r, size(X, 2)));\n",
    "println(pre_err3 == pre_err4)\n",
    "println(V3 == V4)\n",
    "println(W3 == W4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Linear Mixed Models\n",
    "\n",
    "Consider a linear mixed effects model\n",
    "$$\n",
    "\ty_i = \\mathbf{x}_i^T \\beta + \\mathbf{z}_i^T \\gamma + \\epsilon_i, \\quad i=1,\\ldots,n,\n",
    "$$\n",
    "where $\\epsilon_i$ are independent normal errors $N(0,\\sigma_0^2)$, $\\beta \\in \\mathbb{R}^p$ are fixed effects, and $\\gamma \\in \\mathbb{R}^q$ are random effects assumed to be $N(\\mathbf{0}_q, \\sigma_1^2 \\mathbf{I}_q$) independent of $\\epsilon_i$. \n",
    "\n",
    "0. Show that \n",
    "$$\n",
    "    \\mathbf{y} \\sim N \\left( \\mathbf{X} \\beta, \\sigma_0^2 \\mathbf{I}_n + \\sigma_1^2 \\mathbf{Z} \\mathbf{Z}^T \\right),\n",
    "$$\n",
    "where $\\mathbf{y} = (y_1, \\ldots, y_n)^T \\in \\mathbb{R}^n$, $\\mathbf{X} = (\\mathbf{x}_1, \\ldots, \\mathbf{x}_n)^T \\in \\mathbb{R}^{n \\times p}$, and $\\mathbf{Z} = (\\mathbf{z}_1, \\ldots, \\mathbf{z}_n)^T \\in \\mathbb{R}^{n \\times q}$. \n",
    "\n",
    "0. Write a function, with interface \n",
    "    ```julia\n",
    "    logpdf_mvn(y::Vector, Z::Matrix, σ0::Number, σ1::Number),\n",
    "    ```\n",
    "that evaluates the log-density of a multivariate normal with mean $\\mathbf{0}$ and covariance $\\sigma_0^2 \\mathbf{I} + \\sigma_1^2 \\mathbf{Z} \\mathbf{Z}^T$ at $\\mathbf{y}$. Make your code efficient in the $n \\gg q$ case. \n",
    "\n",
    "0. Compare your result (both accuracy and timing) to the [Distributions.jl](http://distributionsjl.readthedocs.io/en/latest/multivariate.html#multivariate-normal-distribution) package using following data.  \n",
    "    ```julia\n",
    "    using BenchmarkTools, Distributions\n",
    "\n",
    "    srand(280)\n",
    "    n, q = 2000, 10\n",
    "    Z = randn(n, q)\n",
    "    σ0, σ1 = 0.5, 2.0\n",
    "    Σ = σ1^2 * Z * Z.' + σ0^2 * I\n",
    "    mvn = MvNormal(Σ) # MVN(0, Σ)\n",
    "    y = rand(mvn) # generate one instance from MNV(0, Σ)\n",
    "\n",
    "    # check you answer matches that from Distributions.jl\n",
    "    @show logpdf_mvn(y, Z, σ0, σ1)\n",
    "    @show logpdf(mvn, y)\n",
    "\n",
    "    # benchmark\n",
    "    @benchmark logpdf_mvn(y, Z, σ0, σ1)\n",
    "    @benchmark logpdf(mvn, y)\n",
    "    ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "87px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
